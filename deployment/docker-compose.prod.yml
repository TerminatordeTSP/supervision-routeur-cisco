# Docker Compose pour production
# Ce fichier peut être utilisé pour remplacer docker-compose.yml en production

services:
  router_django:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: router_django_prod
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - DATABASE=postgres
      - SQL_HOST=db
      - SQL_PORT=5432
      - SQL_USER=user
      - SQL_PASSWORD=password
      - SQL_DATABASE=routerdb
      - DJANGO_SETTINGS_MODULE=router_supervisor.prod_settings
      - DEBUG=False
      - GUNICORN_WORKERS=4
    volumes:
      - static_volume:/code/static
      - media_volume:/code/media
      - ../telegraf/sample_metrics:/tmp/metrics:rw
      - ../logs:/code/logs
    depends_on:
      - db
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  caddy:
    image: caddy:2
    container_name: caddy_prod
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../Caddyfile:/etc/caddy/Caddyfile
      - static_volume:/srv/static
      - media_volume:/srv/media
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - router_django
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  db:
    image: postgres:15
    container_name: postgres_prod
    restart: unless-stopped
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: routerdb
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ../backup:/backup
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d routerdb"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin_prod
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@telecom-sudparis.eu
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # influxdb:
  #   image: influxdb:2.7
  #   container_name: influxdb_prod
  #   restart: unless-stopped
  #   ports:
  #     - "8086:8086"
  #   environment:
  #     - DOCKER_INFLUXDB_INIT_MODE=setup
  #     - DOCKER_INFLUXDB_INIT_USERNAME=admin
  #     - DOCKER_INFLUXDB_INIT_PASSWORD=admin123456
  #     - DOCKER_INFLUXDB_INIT_ORG=telecom-sudparis
  #     - DOCKER_INFLUXDB_INIT_BUCKET=router-metrics
  #     - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=my-super-secret-auth-token
  #   volumes:
  #     - influxdb_data:/var/lib/influxdb2
  #     - influxdb_config:/etc/influxdb2
  #     - ./backup:/backup
  #   healthcheck:
  #     test: ["CMD", "influx", "ping"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 30s
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  # NOTE: InfluxDB est déjà installé sur le serveur, pas besoin du conteneur

  telegraf:
    image: telegraf:1.35
    container_name: telegraf_prod
    restart: unless-stopped
    volumes:
      - ../telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:ro
      - ../telegraf/processors.conf:/etc/telegraf.d/processors.conf:ro
      - ../telegraf/sample_metrics:/tmp/metrics:rw
    depends_on:
      - router_django
    ports:
      - "57500:57500"
    environment:
      - HOST_PROC=/host/proc
      - HOST_SYS=/host/sys
      - HOST_ETC=/host/etc
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    network_mode: "host"  # Utiliser le réseau host pour accéder à l'InfluxDB local

volumes:
  pgdata:
  pgadmin_data:
  static_volume:
  media_volume:
  influxdb_data:
  influxdb_config:
  caddy_data:
  caddy_config:
