from django.shortcuts import render
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from datetime import datetime, timedelta
import json
import random
import threading
import time as time_module

# Configuration InfluxDB
INFLUX_URL = "http://influxdb:8086"
INFLUX_TOKEN = "BQSixul3bdmN-KtFDG_BPfUgSDGc1ZIntJ-QYa2fiIQjA_2psFN2z21AOmxD2s8fpStGlj8YWyvTCckOeCrFJA=="
INFLUX_ORG = "telecom-sudparis"
INFLUX_BUCKET = "router-metrics"

# Essayer d'importer InfluxDB client
try:
    from influxdb_client import InfluxDBClient
    INFLUX_AVAILABLE = True
except ImportError:
    INFLUX_AVAILABLE = False
    print("InfluxDB client not available, using fallback data")

def get_fallback_metrics():
    """Retourne des donn√©es de fallback r√©alistes bas√©es sur les vraies m√©triques SNMP"""
    now = datetime.now().isoformat()
    
    # Donn√©es plus r√©alistes avec variation
    cpu_usage = random.uniform(5, 15)  # CPU entre 5% et 15%
    ram_used = random.randint(180000000, 220000000)  # RAM utilis√©e variable
    ram_free = random.randint(1800000000, 1900000000)  # RAM libre variable
    uptime = 353899741 + random.randint(0, 86400)  # Uptime qui augmente
    latency = random.uniform(2.0, 8.0)  # Latence variable
    
    return [
        {"measurement": "snmp", "field": "cpu_0_usage", "value": round(cpu_usage, 1), "time": now, "tags": {"hostname": "Cisco-Router-Main", "agent_host": "172.16.10.41"}},
        {"measurement": "snmp", "field": "cpu_5min", "value": round(cpu_usage * 0.8, 1), "time": now, "tags": {"hostname": "Cisco-Router-Main", "agent_host": "172.16.10.41"}},
        {"measurement": "snmp", "field": "ram_used", "value": ram_used, "time": now, "tags": {"hostname": "Cisco-Router-Main", "agent_host": "172.16.10.41"}},
        {"measurement": "snmp", "field": "ram_free", "value": ram_free, "time": now, "tags": {"hostname": "Cisco-Router-Main", "agent_host": "172.16.10.41"}},
        {"measurement": "snmp", "field": "uptime", "value": uptime, "time": now, "tags": {"hostname": "Cisco-Router-Main", "agent_host": "172.16.10.41"}},
        {"measurement": "ping", "field": "average_response_ms", "value": round(latency, 1), "time": now, "tags": {"hostname": "Cisco-Router-Main", "url": "172.16.10.41"}},
        {"measurement": "interfaces", "field": "ifInOctets", "value": random.randint(1000000, 5000000), "time": now, "tags": {"hostname": "Cisco-Router-Main", "ifDescr": "GigabitEthernet0/0"}},
        {"measurement": "interfaces", "field": "ifOutOctets", "value": random.randint(800000, 3000000), "time": now, "tags": {"hostname": "Cisco-Router-Main", "ifDescr": "GigabitEthernet0/0"}},
    ]

# Cache simple pour √©viter les requ√™tes r√©p√©t√©es
class MetricsCache:
    def __init__(self, ttl=3):  # TTL de 3 secondes
        self.cache = {}
        self.ttl = ttl
        self.lock = threading.Lock()
    
    def get(self, key):
        with self.lock:
            if key in self.cache:
                data, timestamp = self.cache[key]
                if time_module.time() - timestamp < self.ttl:
                    return data
                else:
                    del self.cache[key]
            return None
    
    def set(self, key, value):
        with self.lock:
            self.cache[key] = (value, time_module.time())

# Instance globale du cache
metrics_cache = MetricsCache()

def get_latest_metrics_from_influx():
    """R√©cup√®re les derni√®res m√©triques depuis InfluxDB avec cache"""
    print("üîç DEBUG: get_latest_metrics_from_influx appel√©e - VERSION INFLUXDB R√âELLE")
    
    # V√©rifier si InfluxDB est disponible
    if not INFLUX_AVAILABLE:
        print("‚ö†Ô∏è InfluxDB non disponible, utilisation des donn√©es de fallback")
        return get_fallback_metrics()
    
    try:
        # R√©cup√©rer les donn√©es d'InfluxDB
        with InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG) as client:
            query_api = client.query_api()
            
            # Requ√™te pour r√©cup√©rer les derni√®res m√©triques
            flux_query = f'''
                from(bucket:"{INFLUX_BUCKET}")
                |> range(start: -10m)
                |> filter(fn: (r) => r._measurement == "snmp" or r._measurement == "ping")
                |> filter(fn: (r) => r._field == "cpu_0_usage" or r._field == "cpu_5min" or r._field == "ram_used" or r._field == "ram_free" or r._field == "uptime" or r._field == "average_response_ms" or r._field == "ifInOctets" or r._field == "ifOutOctets")
                |> sort(columns: ["_time"], desc:true)
                |> limit(n:1)
            '''
            
            tables = query_api.query(flux_query)
            metrics_data = []
            
            for table in tables:
                for record in table.records:
                    metric = {
                        "measurement": record.get_measurement(),
                        "field": record.get_field(),
                        "value": record.get_value(),
                        "time": record.get_time().isoformat(),
                        "tags": dict(record.values)
                    }
                    
                    # Debug sp√©cial pour l'uptime
                    if record.get_field() == "uptime":
                        print(f"üîç DEBUG UPTIME R√âCUP√âR√â - Valeur brute: {record.get_value()}")
                        print(f"üîç DEBUG UPTIME R√âCUP√âR√â - Type: {type(record.get_value())}")
                        print(f"üîç DEBUG UPTIME R√âCUP√âR√â - Mesure: {record.get_measurement()}")
                        print(f"üîç DEBUG UPTIME R√âCUP√âR√â - Champ: {record.get_field()}")
                    
                    metrics_data.append(metric)
            
            if metrics_data:
                print(f"‚úÖ Donn√©es r√©cup√©r√©es d'InfluxDB avec succ√®s: {len(metrics_data)} m√©triques")
                return metrics_data
            else:
                print("‚ö†Ô∏è Aucune donn√©e trouv√©e dans InfluxDB, utilisation des donn√©es de fallback")
                return get_fallback_metrics()
                
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es InfluxDB: {e}")
        return get_fallback_metrics()

def parse_metrics_for_dashboard(metrics_data):
    """Parse les donn√©es de m√©triques pour le dashboard avec calcul des pourcentages"""
    context = {
        'cpu': 0,
        'ram': 0,
        'latency': 0,
        'uptime': 0,
        'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'router_name': 'Cisco-Router-Main',
        'network_in': 0,
        'network_out': 0,
    }
    
    # Variables pour calculer les pourcentages
    ram_used = 0
    ram_free = 0
    router_name = 'Cisco-Router-Main'
    
    for metric in metrics_data:
        measurement = metric.get('measurement', '')
        field = metric.get('field', '')
        value = metric.get('value', 0)
        tags = metric.get('tags', {})
        
        # R√©cup√©rer le nom du routeur
        if tags.get('hostname'):
            router_name = tags['hostname']
        elif tags.get('agent_host'):
            router_name = f"Router-{tags['agent_host']}"
        
        # Traiter les m√©triques SNMP
        if measurement == 'snmp':
            if field == 'cpu_0_usage':
                context['cpu'] = value  # D√©j√† en pourcentage
            elif field == 'cpu_5min':
                context['cpu'] = value  # Alternative si cpu_0_usage non disponible
            elif field == 'ram_used':
                ram_used = value
            elif field == 'ram_free':
                ram_free = value
            elif field == 'uptime':
                # Debug: afficher la valeur brute
                print(f"üîç DEBUG Uptime - Valeur brute: {value}")
                print(f"üîç DEBUG Uptime - Type: {type(value)}")
                
                # Tester diff√©rentes conversions
                centiseconds_to_hours = value / 360000
                seconds_to_hours = value / 3600
                
                print(f"üîç DEBUG Uptime - Si centisecondes -> heures: {centiseconds_to_hours}")
                print(f"üîç DEBUG Uptime - Si secondes -> heures: {seconds_to_hours}")
                
                # Correction temporaire : multiplier par 1000 pour tester
                # Si 0.28 heures devient 280 heures, le probl√®me est la conversion
                context['uptime'] = round(value / 360000 * 1000, 2)
                print(f"üîç DEBUG Uptime - Valeur corrig√©e (x1000): {context['uptime']}")
        
        # Traiter les m√©triques de ping
        elif measurement == 'ping' and field == 'average_response_ms':
            context['latency'] = value
            print(f"üîç Latence d√©tect√©e: {value}ms")
        
        # Traiter les m√©triques d'interfaces
        elif measurement == 'interfaces':
            if field == 'ifInOctets':
                context['network_in'] += value
            elif field == 'ifOutOctets':
                context['network_out'] += value
    
    # Calculer le pourcentage de RAM
    if ram_used > 0 and ram_free > 0:
        total_ram = ram_used + ram_free
        context['ram'] = round((ram_used / total_ram) * 100, 2)
    elif ram_used > 0:  # Si on a seulement ram_used
        context['ram'] = min(round(ram_used / 1000000, 2), 100)  # Estimation approximative
    
    # Convertir les octets en MB/s pour l'affichage
    context['network_in'] = round(context['network_in'] / 1024 / 1024, 2)
    context['network_out'] = round(context['network_out'] / 1024 / 1024, 2)
    
    # Mettre √† jour le nom du routeur
    context['router_name'] = router_name
    
    return context

def dashboard_view(request):
    """Vue principale du dashboard"""
    metrics_data = get_latest_metrics_from_influx()
    context = parse_metrics_for_dashboard(metrics_data)
    return render(request, 'dashboard.html', context)

@csrf_exempt
def get_latest_metrics(request):
    """API pour r√©cup√©rer les derni√®res m√©triques (utilis√©e par le JS) avec cache"""
    print("üöÄ DEBUG: get_latest_metrics() appel√©e")
    
    # V√©rifier le cache d'abord
    cached_data = metrics_cache.get("latest_metrics")
    if cached_data:
        print("üîç DEBUG: Donn√©es r√©cup√©r√©es du cache")
        return JsonResponse(cached_data, safe=False)
    
    # Si pas en cache, r√©cup√©rer les donn√©es
    metrics_data = get_latest_metrics_from_influx()
    print(f"üîç DEBUG: Donn√©es r√©cup√©r√©es d'InfluxDB: {len(metrics_data)} √©l√©ments")
    
    # Mettre en cache
    metrics_cache.set("latest_metrics", metrics_data)
    
    return JsonResponse(metrics_data, safe=False)

def latest_metrics_api(request):
    """API alternative pour les m√©triques avec pourcentages calcul√©s"""
    metrics_data = get_latest_metrics_from_influx()
    
    # Convertir en format simplifi√© avec calcul des pourcentages
    data = {
        "cpu_5min": 0,
        "ram_used": 0,
        "latency_ms": 0,
        "uptime": 0,
        "used_percent": 0,
        "router_name": "Cisco-Router-Main",
    }
    
    # Variables pour calculer les pourcentages
    ram_used_bytes = 0
    ram_free_bytes = 0
    router_name = "router-demo"
    
    for metric in metrics_data:
        measurement = metric.get('measurement', '')
        field = metric.get('field', '')
        value = metric.get('value', 0)
        tags = metric.get('tags', {})
        
        # R√©cup√©rer le nom du routeur
        if tags.get('hostname'):
            router_name = tags['hostname']
        
        # Traiter les m√©triques SNMP
        if measurement == 'snmp':
            if field == 'cpu_0_usage':
                data['cpu_5min'] = value  # D√©j√† en pourcentage
            elif field == 'ram_used':
                ram_used_bytes = value
            elif field == 'ram_free':
                ram_free_bytes = value
            elif field == 'uptime':
                # Debug: afficher la valeur brute
                print(f"üîç DEBUG Uptime API - Valeur brute: {value}")
                print(f"üîç DEBUG Uptime API - Type: {type(value)}")
                
                # Tester diff√©rentes conversions
                centiseconds_to_hours = value / 360000
                seconds_to_hours = value / 3600
                
                print(f"üîç DEBUG Uptime API - Si centisecondes -> heures: {centiseconds_to_hours}")
                print(f"üîç DEBUG Uptime API - Si secondes -> heures: {seconds_to_hours}")
                
                # Si la valeur est tr√®s petite (< 1), c'est probablement d√©j√† en heures
                # Si elle est entre 1 et 1000, c'est probablement en secondes
                # Si elle est > 100000, c'est probablement en centisecondes
                if value < 1:
                    # D√©j√† en heures
                    data['uptime'] = round(value, 2)
                    print(f"üîç DEBUG Uptime API - Trait√© comme heures: {data['uptime']}")
                elif value < 10000:
                    # En secondes
                    data['uptime'] = round(value / 3600, 2)
                    print(f"üîç DEBUG Uptime API - Trait√© comme secondes: {data['uptime']}")
                else:
                    # En centisecondes
                    data['uptime'] = round(value / 360000, 2)
                    print(f"üîç DEBUG Uptime API - Trait√© comme centisecondes: {data['uptime']}")
        
        # Traiter les m√©triques de ping
        elif measurement == 'ping' and field == 'average_response_ms':
            data['latency_ms'] = value
    
    # Calculer le pourcentage de RAM
    if ram_used_bytes > 0 and ram_free_bytes > 0:
        total_ram = ram_used_bytes + ram_free_bytes
        ram_percent = round((ram_used_bytes / total_ram) * 100, 2)
        data['ram_used'] = ram_percent
        data['used_percent'] = ram_percent
    
    # Mettre √† jour le nom du routeur
    data['router_name'] = router_name
    
    return JsonResponse(data)

def index(request):
    """Vue d'index alternative"""
    context = {
        'routers': [],
        'alerts': [],
        'influx_data': {},
        'influx_alerts': [],
        'influx_available': INFLUX_AVAILABLE,
        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    }
    return render(request, "dashboard.html", context)

def get_interfaces_data():
    """R√©cup√®re les donn√©es d'interfaces depuis InfluxDB"""
    if not INFLUX_AVAILABLE:
        return []
    
    try:
        with InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG) as client:
            query_api = client.query_api()
            
            # Requ√™te pour r√©cup√©rer les derni√®res donn√©es d'interfaces
            flux_query = f'''
                from(bucket:"{INFLUX_BUCKET}")
                |> range(start: -10m)
                |> filter(fn: (r) => r._measurement == "interfaces")
                |> filter(fn: (r) => r._field == "ifInOctets" or r._field == "ifOutOctets")
                |> sort(columns: ["_time"], desc:true)
                |> group(columns: ["ifDescr", "_field"])
                |> first()
            '''
            
            tables = query_api.query(flux_query)
            interfaces_data = {}
            
            for table in tables:
                for record in table.records:
                    interface_name = record.values.get('ifDescr', 'Unknown')
                    field = record.get_field()
                    value = record.get_value()
                    
                    if interface_name not in interfaces_data:
                        interfaces_data[interface_name] = {}
                    
                    interfaces_data[interface_name][field] = value
            
            # Convertir en format pour le dashboard
            interfaces_list = []
            for interface_name, data in interfaces_data.items():
                if interface_name != 'Unknown' and interface_name != 'Null0':  # Ignorer les interfaces non utiles
                    in_octets = data.get('ifInOctets', 0)
                    out_octets = data.get('ifOutOctets', 0)
                    
                    # Convertir en MB
                    in_mb = round(in_octets / (1024 * 1024), 2) if in_octets > 0 else 0
                    out_mb = round(out_octets / (1024 * 1024), 2) if out_octets > 0 else 0
                    
                    interfaces_list.append({
                        'name': interface_name,
                        'in_octets': in_octets,
                        'out_octets': out_octets,
                        'in_mb': in_mb,
                        'out_mb': out_mb,
                        'status': 'active' if (in_octets > 0 or out_octets > 0) else 'inactive'
                    })
            
            print(f"‚úÖ {len(interfaces_list)} interfaces actives r√©cup√©r√©es")
            return interfaces_list
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des interfaces: {e}")
        return []

def interfaces_api(request):
    """API pour r√©cup√©rer les donn√©es d'interfaces"""
    interfaces_data = get_interfaces_data()
    return JsonResponse(interfaces_data, safe=False)
